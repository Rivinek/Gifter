{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import gensim\n",
    "from gifter.modeling.data import lemmatized_frame\n",
    "from gifter.modeling.tokenizer import lemmatize\n",
    "from gensim import corpora\n",
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LDA(texts=[\"default\"], num=2, passes=100):\n",
    "    if (texts == [\"default\"]):\n",
    "        df = lemmatized_frame(\"../data.json\", with_tags=False)\n",
    "        texts = [df['lemmas'].irow(i) for i in range(df.shape[0])]\n",
    "    else:\n",
    "        texts2 = []\n",
    "        for d in texts:\n",
    "            texts2 = texts2 + [lemmatize(d, with_tags=False)]\n",
    "            texts = texts2\n",
    "    dictionary = corpora.Dictionary(texts)\n",
    "    corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "    #print \"corpus: \" + str(corpus)\n",
    "    corpora.MmCorpus.serialize('./corpus.mm', corpus)\n",
    "    mm_corpus = corpora.MmCorpus('./corpus.mm')\n",
    "    #print \"mm_corpus: \" + str(mm_corpus)\n",
    "    id2word = {}\n",
    "    for word in dictionary.token2id:\n",
    "        id2word[dictionary.token2id[word]] = word\n",
    "    #lda = gensim.models.ldamodel.LdaModel(\n",
    "    lda = gensim.models.ldamulticore.LdaMulticore(\n",
    "        corpus=mm_corpus,\n",
    "        num_topics=num,\n",
    "        id2word=id2word,\n",
    "        #update_every=1,\n",
    "        eval_every=1,\n",
    "        passes=passes,\n",
    "        workers=1\n",
    "    )\n",
    "    for i in range(0, lda.num_topics):\n",
    "        print \"Topic number \" + str(i) + \" consists of words : \" + lda.print_topic(i)\n",
    "    return lda, dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ponizej algorytm nauczony jest na kontach 2 sportowców i 2 polityków na Twiterze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marta/Desktop/Gifter/gifter/modeling/tokenizer.py:55: RuntimeWarning: Argument <type 'str'> is not an unicode object. Passing an encoded string will likely have unexpected results.\n",
      "  pattern = re.compile(\"(#|RT |{})\".format(unidecode(to_remove)), re.I)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic number 0 consists of words : 0.016*state + 0.010*secretary + 0.009*win + 0.009*curry + 0.008*lead + 0.008*game + 0.008*minister + 0.007*conservative + 0.007*amp + 0.006*steph\n",
      "Topic number 1 consists of words : 0.029*fcb + 0.013*president + 0.010*atleti + 0.009*obama + 0.009*atm + 0.008*campion + 0.008*title + 0.008*climate + 0.008*best + 0.007*celebrate\n"
     ]
    }
   ],
   "source": [
    "l, dic = LDA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_topic(new_doc=\"User\", dictionary=dic, lda=l):\n",
    "    if (new_doc == \"User\"):\n",
    "        df = lemmatized_frame(\"../test.json\", with_tags=False)\n",
    "        new_doc = list(\n",
    "            itertools.chain(\n",
    "                *[df['lemmas'].irow(i) for i in range(df.shape[0])]\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        new_doc = new_doc.lower().split()\n",
    "    new_vec = dictionary.doc2bow(new_doc)\n",
    "    vec_lda = sorted(lda[new_vec], key=lambda vec: vec[1], reverse=True)\n",
    "    print str(vec_lda)\n",
    "    print \"Top topic is topic number \" + str(\n",
    "        vec_lda[0][0]\n",
    "    ) + \" consists of words : \" + lda.print_topic(vec_lda[0][0])\n",
    "    return vec_lda\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poniżej sprawdzony został zbiór tweetów dla użytkownika @BBC Politics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 0.64588987562353839), (0, 0.35411012437646155)]\n",
      "Top topic is topic number 1 consists of words : 0.029*fcb + 0.013*president + 0.010*atleti + 0.009*obama + 0.009*atm + 0.008*campion + 0.008*title + 0.008*climate + 0.008*best + 0.007*celebrate\n",
      "CPU times: user 881 ms, sys: 52.1 ms, total: 933 ms\n",
      "Wall time: 921 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1, 0.64588987562353839), (0, 0.35411012437646155)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time find_topic()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poniżej został sprawdzony zbiór tweetow dla użytkownika @ESPNBoxing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 0.67294637348706599), (0, 0.32705362651293401)]\n",
      "Top topic is topic number 1 consists of words : 0.029*fcb + 0.013*president + 0.010*atleti + 0.009*obama + 0.009*atm + 0.008*campion + 0.008*title + 0.008*climate + 0.008*best + 0.007*celebrate\n",
      "CPU times: user 535 ms, sys: 8.99 ms, total: 544 ms\n",
      "Wall time: 537 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1, 0.67294637348706599), (0, 0.32705362651293401)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time find_topic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
